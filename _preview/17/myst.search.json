{"version":"1","records":[{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"content":" ","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"type":"lvl1","url":"/#investigating-interhemispheric-precipitation-changes-over-the-past-millennium","position":2},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"content":"\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers paleoclimate model-data comparison using spatio-temporal pattern obtained using Principal Component Analysis (PCA).","type":"content","url":"/#investigating-interhemispheric-precipitation-changes-over-the-past-millennium","position":3},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":4},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Motivation"},"content":"Paleoclimate observations obtained from tree rings or the geochemical composition of speleothems, ice and sediments provide an out-of-sample validation of climate models. However, comparing the output of climate models directly with the paleoclimate observations is difficult: (1) they are often expressed in different quantities (i.e., temperature vs ring width), (2) paleoclimate observations have large time uncertainties, (3) paleoclimate observations often incorporate more than one environmental signal (i.e., temperature AND moisture).\n\nRecently, \n\nSteinman et al. (2022) used PCA analysis to compare model and data output. Here, we use a similar approach with the \n\nCESM Last Millennium simulation and proxy records stored on the \n\nLiPDverse. This repository contains paleoclimate datasets that have been curated by the community and are archived in a standard format, facilitating analysis.","type":"content","url":"/#motivation","position":5},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":6},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Authors"},"content":"Deborah Khider, \n\nHari Sundar, \n\nVarun Ratnakar","type":"content","url":"/#authors","position":7},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":8},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":9},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":10},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Structure"},"content":"This Cookbook is broken down into three main sections. The first section performs the PCA analysis on the output of the CESM LME simulation. The second section performs the same analysis on paleoclimate observations. The last section compares the two analyses.","type":"content","url":"/#structure","position":11},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"PCA analysis on proxy observations","lvl2":"Structure"},"type":"lvl3","url":"/#pca-analysis-on-proxy-observations","position":12},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"PCA analysis on proxy observations","lvl2":"Structure"},"content":"The section shows the query used to obtain relevant proxy datasets from a graphDB mirroring the LiPDverse data, filtering for records that cover at least 1500 of the last 2000 years with a resolution better than 60 years, and running PCA.","type":"content","url":"/#pca-analysis-on-proxy-observations","position":13},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"PCA analysis on the CESM Last Millennium Analysis¶","lvl2":"Structure"},"type":"lvl3","url":"/#pca-analysis-on-the-cesm-last-millennium-analysis","position":14},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"PCA analysis on the CESM Last Millennium Analysis¶","lvl2":"Structure"},"content":"The section walks through fetching the data from JetStream2, calculating the precipitation d18O and running PCA.","type":"content","url":"/#pca-analysis-on-the-cesm-last-millennium-analysis","position":15},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Model Data Comparison","lvl2":"Structure"},"type":"lvl3","url":"/#model-data-comparison","position":16},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Model Data Comparison","lvl2":"Structure"},"content":"Visualizing the output of the PCA analyses.","type":"content","url":"/#model-data-comparison","position":17},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":18},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":19},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":20},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/#running-on-binder","position":21},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":22},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/paleoPCA-Cookbook repository: git clone https://github.com/ProjectPythia/paleoPCA-Cookbook.git\n\nMove into the paleoPCA-Cookbook directorycd paleoPCA-Cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate paleoPCA-Cookbook\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":23},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"type":"lvl1","url":"/notebooks/paleopca","position":0},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"content":"\n\n\n","type":"content","url":"/notebooks/paleopca","position":1},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"type":"lvl1","url":"/notebooks/paleopca#investigating-interhemispheric-precipitation-changes-over-the-past-millennium","position":2},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium"},"content":"\n\n\n\n","type":"content","url":"/notebooks/paleopca#investigating-interhemispheric-precipitation-changes-over-the-past-millennium","position":3},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/paleopca#overview","position":4},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Overview"},"content":"This CookBook demonstrates how to compare paleoclimate model output and proxy observations using EOF to identify large-scale spatio-temporal patterns in the data. It is inspired from a study by \n\nSteinman et al. (2022) although it reuses different datasets.\n\n","type":"content","url":"/notebooks/paleopca#overview","position":5},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/paleopca#prerequisites","position":6},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nIntro to Matplotlib\n\nNecessary\n\n\n\nIntro to Pandas\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nNecessary\n\n\n\nUsing xarray\n\nNecessary\n\nFamiliarity with understanding opening multiple files and merging\n\nEOF (PCA) Analysis - See Chapter 12 of \n\nthis book\n\nHelpful\n\nFamiliarity with the concepts is helpful for interpretation of the results\n\neofs package\n\nHelpful\n\nA good introduction on the package can be found in \n\nthis notebook\n\nUsing Pyleoclim for Paleoclimate Data\n\nHelpful\n\n\n\nSPARQL\n\nFamiliarity\n\nQuery language for graph database\n\nTime to learn: 40 min.\n\n\n\n","type":"content","url":"/notebooks/paleopca#prerequisites","position":7},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/paleopca#imports","position":8},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Imports"},"content":"\n\n#To deal with model data\nimport s3fs\nimport fsspec\nimport xarray as xr\nimport glob\n\n#To deal with proxy data\nimport pandas as pd\nimport numpy as np\nimport json\nimport requests\nimport pandas as pd\nimport io\nimport ast\n\n#To deal with analysis\nimport pyleoclim as pyleo\nfrom eofs.xarray import Eof\n\n#Plotting and mapping\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport nc_time_axis\nfrom matplotlib import gridspec\nfrom matplotlib.colors import Normalize\n\n","type":"content","url":"/notebooks/paleopca#imports","position":9},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"PCA analysis on proxy observations"},"type":"lvl2","url":"/notebooks/paleopca#pca-analysis-on-proxy-observations","position":10},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"PCA analysis on proxy observations"},"content":"After looking at the model data, let’s have a look at the proxy datasets.\n\n","type":"content","url":"/notebooks/paleopca#pca-analysis-on-proxy-observations","position":11},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Query to remote database","lvl2":"PCA analysis on proxy observations"},"type":"lvl3","url":"/notebooks/paleopca#query-to-remote-database","position":12},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Query to remote database","lvl2":"PCA analysis on proxy observations"},"content":"The first step is the query the \n\nLinkedEarth Graph Database for relevant datasets for comparison with the model.\n\nThe database uses the SPARQL language for queries. We are filtering the database for the following criteria:\n\nDatasets bounded by 27°S-27°N and 70°W-150°W\n\nDatasets from the \n\nPages2k, \n\nIso2k, \n\nCoralHydro2k and \n\nSISAL working groups. These working groups identified archived datasets that were sensitive to temperature and the isotopic composition of precipication (precipitation \\delta{18}O) and curated them for use in a standardized database.\n\nTimeseries within these datasets representing precipitation.\n\nWe asked for the following information back:\n\nThe name of the dataset\n\nGeographical Location of the record expressed in latitude and longitude\n\nThe type of archive (e.g., speleothem, Lake sediment) the measurements were made on\n\nThe name of the variable\n\nThe values and units of the measurements\n\nThe time information (values and units) associated with the variable of interest.\n\nThe following cell points to the query API and creates the query itself.\n\nurl = 'https://linkedearth.graphdb.mint.isi.edu/repositories/LiPDVerse-dynamic'\n\nquery = \"\"\"PREFIX le: <http://linked.earth/ontology#>\nPREFIX wgs84: <http://www.w3.org/2003/01/geo/wgs84_pos#>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nSELECT distinct?varID ?dataSetName ?lat ?lon ?varname ?interpLabel ?val ?varunits ?timevarname ?timeval ?timeunits ?archiveType where{\n\n    ?ds a le:Dataset .\n    ?ds le:hasName ?dataSetName .\n    OPTIONAL{?ds le:hasArchiveType ?archiveTypeObj .\n             ?archiveTypeObj rdfs:label ?archiveType .}\n    \n    \n    ?ds le:hasLocation ?loc .\n    ?loc wgs84:lat ?lat .\n    FILTER(?lat<26 && ?lat>-26) \n    ?loc wgs84:long ?lon .\n    FILTER(?lon<-70 && ?lon>-150) \n    \n    ?ds le:hasPaleoData ?data .\n    ?data le:hasMeasurementTable ?table .\n    ?table le:hasVariable ?var .\n    ?var le:hasName ?varname .\n    VALUES ?varname {\"d18O\"} .\n    ?var le:partOfCompilation  ?comp .\n    ?comp le:hasName ?compName .\n    VALUES ?compName {\"iso2k\" \"Pages2kTemperature\" \"CoralHydro2k\" \"SISAL-LiPD\"} .\n    ?var le:hasInterpretation ?interp .\n    ?interp le:hasVariable ?interpVar .\n    ?interpVar rdfs:label ?interpLabel .\n    FILTER (REGEX(?interpLabel, \"precipitation.*\", \"i\"))\n    ?var le:hasVariableId ?varID .\n    ?var le:hasValues ?val .\n    OPTIONAL{?var le:hasUnits ?varunitsObj .\n    \t\t?varunitsObj rdfs:label ?varunits .}\n    \n    ?table le:hasVariable ?timevar .\n    ?timevar le:hasName ?timevarname .\n    VALUES ?timevarname {\"year\" \"age\"} .\n    ?timevar le:hasValues ?timeval .\n    OPTIONAL{?timevar le:hasUnits ?timeunitsObj .\n    \t\t ?timeunitsObj rdfs:label ?timeunits .}  \n}\"\"\"\n\nThe following cell sends the query to the database and returns the results in a Pandas Dataframe.\n\nresponse = requests.post(url, data = {'query': query})\n\ndata = io.StringIO(response.text)\ndf_res = pd.read_csv(data, sep=\",\")\n\ndf_res['val']=df_res['val'].apply(lambda row : json.loads(row) if isinstance(row, str) else row)\ndf_res['timeval']=df_res['timeval'].apply(lambda row : json.loads(row) if isinstance(row, str) else row)\n\ndf_res.head()\n\nWe have retrieved the following number of proxy records:\n\nlen(df_res)\n\nMake sure we have unique timeseries (some may be found across compilations):\n\ndf = df_res[~df_res['varID'].duplicated()]\n\nlen(df)\n\nThe first step is to make sure that everything is on the same representation of the time axis. Year is considered prograde while age is considered retrograde:\n\ndf['timevarname'].unique()\n\nSince we have records expressed in both year and age, let’s convert everything to year. First let’s have a look at the units:\n\ndf['timeunits'].unique()\n\nThe units for age are expressed in BP (before present), if we assume the present to be 1950 by convention, then we can transform:\n\ndf['timeval'] = df['timeval'].apply(np.array)\n\ndef adjust_timeval(row):\n    if row['timevarname'] == 'age':\n        return 1950 - row['timeval']\n    else:\n        return row['timeval']\n\n# Apply the function across the DataFrame rows\ndf['timeval'] = df.apply(adjust_timeval, axis=1)\n\nIt is obvious that some of the timeseries do not have correct time information (e.g., row 2). Let’s filter the dataframe to make sure that the time values are within 0-2000 and that there is at least 1500 years of record:\n\ndef range_within_limits(array, lower = 0, upper = 2000, threshold = 1500):\n    filtered_values = array[(array >= lower) & (array <= upper)]\n    if filtered_values.size > 0:  # Check if there are any values within the range\n        return np.ptp(filtered_values) >= threshold  # np.ptp() returns the range of values\n    return False  # If no values within the range, filter out the row\n\n\n# Apply the function to filter the DataFrame\nfiltered_df = df[df['timeval'].apply(range_within_limits)]\n\nWe are now left with:\n\nlen(filtered_df)\n\nLet’s also make sure that the records are long enough (i.e., more than 1500 years long):\n\ndef array_range_exceeds(array, threshold=1500):\n    return np.max(array) - np.min(array) > threshold\n\nfilt_df = filtered_df[filtered_df['timeval'].apply(array_range_exceeds)]\n\nThis leaves us with the following number of datasets:\n\nlen(filt_df)\n\nLet’s filter for records with a resolution finer or equal to 60 years:\n\ndef min_resolution(array, min_res=60):\n    if len(array) > 1:  # Ensure there are at least two points to calculate a difference\n        # Calculate differences between consecutive elements\n        differences = np.mean(np.diff(array))\n        # Check if the minimum difference is at least 50\n        return abs(differences) <= min_res\n    return False  # If less than two elements, can't compute difference\n\n# Apply the function and filter the DataFrame\nfiltered_df2 = filt_df[filt_df['timeval'].apply(min_resolution)]\n\nThis leaves us with the following number of datasets:\n\nlen(filtered_df2)\n\nNext, let’s use the \n\nPyleoclim software package and create individual \n\nGeoSeries objects:\n\nts_list = []\nfor _, row in filtered_df2.iterrows():\n        ts_list.append(pyleo.GeoSeries(time=row['timeval'],value=row['val'],\n                                   time_name='year',value_name=row['varname'],\n                                   time_unit='CE', value_unit=row['varunits'],\n                                   lat = row['lat'], lon = row['lon'],\n                                   archiveType = row['archiveType'], verbose = False, \n                                   label=row['dataSetName']+'_'+row['varname']))\n\n        #print(row['timeval'])\n\nNow let’s use a \n\nMultipleGeoSeries object for visualization and analysis:\n\nmgs = pyleo.MultipleGeoSeries(ts_list, label='HydroAm2k', time_unit='year CE') \n\nLet’s first map the location of the records by the type of archive:\n\nmgs.map()\n\nLet’s have a look at the records, sliced for the 0-2000 period\n\nfig, ax = mgs.sel(time=slice(0,2000)).stackplot(v_shift_factor=1.2)\nplt.show(fig)\n\n","type":"content","url":"/notebooks/paleopca#query-to-remote-database","position":13},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Run PCA Analysis","lvl2":"PCA analysis on proxy observations"},"type":"lvl3","url":"/notebooks/paleopca#run-pca-analysis","position":14},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Run PCA Analysis","lvl2":"PCA analysis on proxy observations"},"content":"Let’s place them on a common time axis for analysis and standardize:\n\nmgs_common = mgs.sel(time=slice(850,2000)).common_time().standardize()\n\npca = mgs_common.pca()\n\nLet’s have a look at the screeplot:\n\npca.screeplot()\n\nAs is nearly always the case with geophysical timeseries, the first few of eigenvalues trully overwhelm the rest. In this case, let’s have a look at the first three.\n\npca.modeplot()\n\nLet’s have a look at the second mode:\n\npca.modeplot(index=1)\n\nFinally, let’s have a look at the third mode:\n\npca.modeplot(index=2)\n\nAs you can see, the first three modes explain 60% of the variance.\n\n","type":"content","url":"/notebooks/paleopca#run-pca-analysis","position":15},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"type":"lvl2","url":"/notebooks/paleopca#pca-analysis-on-the-cesm-last-millennium-ensemble","position":16},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"content":"\n\nThe first step is the calculate precipitation \\delta^{18}O for the all forcings simulation. The following section demonstrates how to get the data from JetStream2 and pre-process each file to save the needed variable and place them into a new xarray.Dataset. This process can be time-consuming.","type":"content","url":"/notebooks/paleopca#pca-analysis-on-the-cesm-last-millennium-ensemble","position":17},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Get the CESM Last Millennium Ensemble data from JetStream2","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"type":"lvl3","url":"/notebooks/paleopca#get-the-cesm-last-millennium-ensemble-data-from-jetstream2","position":18},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Get the CESM Last Millennium Ensemble data from JetStream2","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"content":"Let’s open the needed files for this analysis, which consists of various precipitation isotopes. All data have been made available on NSF JetStream2.\n\nURL = 'https://js2.jetstream-cloud.org:8001/' #Locate and read a file\n\npath = f'pythia/cesmLME' # specify data location\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL)) \npattern = f's3://{path}/*.nc'\nfiles = sorted(fs.glob(pattern))\n\nLet’s open relevant files for the all forcing simulations (‘LME.002’) for the 850-1850 period:\n\nbase_name = 'pythia/cesmLME/b.ie12.B1850C5CN.f19_g16.LME.002.cam.h0.'\ntime_period =  '085001-184912'\n\nnames = [name for name in files if base_name in name and time_period in name]\n\nnames\n\nfileset = [fs.open(file) for file in names]\n\nNext, let’s open these datasets and extract the needed variables into another xarray.Dataset.\n\nWarningNote that this cell may take some time to run! On a 2024 MacBook pro with an M3 chip, it took about 7minutes.\n\n%%time\nfor idx,item in enumerate(fileset):\n    ds_u = xr.open_dataset(item)\n    var_name = names[idx].split('.')[-3] #This uses the file name to obtain the variable name. \n    da = ds_u[var_name]\n    try:\n        ds[var_name]= da\n    except:\n        ds = da.to_dataset()\n        ds.attrs = ds_u.attrs \n    ds_u.close()\n    da.close()\n\nAnd we’re done! Let’s have a look at the data we will be working with:\n\nds\n\n","type":"content","url":"/notebooks/paleopca#get-the-cesm-last-millennium-ensemble-data-from-jetstream2","position":19},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Select the tropical Central and South America region","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"type":"lvl3","url":"/notebooks/paleopca#select-the-tropical-central-and-south-america-region","position":20},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Select the tropical Central and South America region","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"content":"Let’s look at the region bounded by 27°S-27°N and 70°W-150°W:\n\nds_geo_all = ds.sel(lat=slice(-27,27), lon=slice(250,330))\n\nSince the loading and pre-processing of the files take a long time, let’s save a version of this dataset in netCDF for further use:\n\n#ds_geo.to_netcdf(path='../data/LME.002.cam.h0.precip_iso.085001-184912.nc')\n\nFor model-data comparison, it might be useful to resample the model data on the proxy scales:\n\nprint(\"The minimum time is: \"+str(np.min(mgs_common.series_list[0].time)))\nprint(\"The maximum time is: \"+str(np.max(mgs_common.series_list[0].time)))\nprint(\"The resolution is: \"+str(np.mean(np.diff(mgs_common.series_list[0].time))))\n\nds_geo_time = ds_geo_all.sel(time=slice(\"0910-01-01 00:00:00\" ,\"1642-12-01 00:00:00\"))\n\nAnd resample to the proxy resolution (~20yr as calculated above):\n\nds_geo = ds_geo_time.resample(time='20A').mean()\n\nds_geo\n\n","type":"content","url":"/notebooks/paleopca#select-the-tropical-central-and-south-america-region","position":21},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Calculate Precipitation \\delta^{18}O","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"type":"lvl3","url":"/notebooks/paleopca#calculate-precipitation-delta-18-o","position":22},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Calculate Precipitation \\delta^{18}O","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"content":"\n\n%%time\np16O = ds_geo['PRECRC_H216Or'] + ds_geo['PRECSC_H216Os'] + ds_geo['PRECRL_H216OR'] + ds_geo['PRECSL_H216OS']\np18O = ds_geo['PRECRC_H218Or'] + ds_geo['PRECSC_H218Os'] + ds_geo['PRECRL_H218OR'] + ds_geo['PRECSL_H218OS']\n\np16O = p16O.where(p16O > 1e-18, 1e-18)\np18O = p18O.where(p18O > 1e-18, 1e-18)\n\nd18Op = (p18O / p16O - 1)*1000\n\n","type":"content","url":"/notebooks/paleopca#calculate-precipitation-delta-18-o","position":23},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Run PCA analysis","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"type":"lvl3","url":"/notebooks/paleopca#run-pca-analysis-1","position":24},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Run PCA analysis","lvl2":"PCA analysis on the CESM Last Millennium Ensemble"},"content":"Let’s first standardize the data:\n\nd18Oa = (d18Op - d18Op.mean(dim='time'))/d18Op.std(dim='time')\n\nCreate an EOF solver to do the EOF analysis.\n\nsolver = Eof(d18Oa, weights=None)\n\nRetrieve the leading EOF, expressed as the covariance between the leading PC time series and the input d18O anomalies at each grid point.\n\neof1 = solver.eofsAsCovariance(neofs=3)\n\nPlot the leading EOF expressed covariance\n\nclevs = np.linspace(-1, 1, 20)\nproj = ccrs.PlateCarree(central_longitude=290)\nfig, ax = plt.subplots(figsize=[10,4], subplot_kw=dict(projection=proj))\nax.coastlines()\neof1[0].plot.contourf(ax=ax, levels = clevs, cmap=plt.cm.RdBu_r,\n                         transform=ccrs.PlateCarree(), add_colorbar=True)\nfig.axes[1].set_ylabel('')\nfig.axes[1].set_yticks(np.arange(-1,1.2,0.2))\nax.set_title('EOF1 expressed as covariance', fontsize=16)\nplt.show()\n\nLet’s have a look at the first three PCs:\n\npcs = solver.pcs(npcs=3, pcscaling=1)\n\nfig, ax = plt.subplots(figsize=[20,4])\npcs[:, 0].plot(ax=ax, linewidth=1)\nax = plt.gca()\nax.axhline(0, color='k')\nax.set_ylim(-3, 3)\nax.set_xlabel('Year')\nax.set_ylabel('Normalized Units')\nax.set_title('PC1 Time Series', fontsize=16)\n\n","type":"content","url":"/notebooks/paleopca#run-pca-analysis-1","position":25},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Model-Data Comparison"},"type":"lvl2","url":"/notebooks/paleopca#model-data-comparison","position":26},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Model-Data Comparison"},"content":"Let’s map the first EOF for the model and data and the first PC.\n\n# Create a figure\n\nfig = plt.figure(figsize=[20,8])\n\n# Define the GridSpec\ngs = gridspec.GridSpec(1, 2, figure=fig)\n\n# Add a geographic map in the first subplot using Cartopy\n\nax1 = fig.add_subplot(gs[0, 0], projection=ccrs.PlateCarree(central_longitude=290))\nax1.coastlines()  # Add coastlines to the map\n\n# Plot the model results\nnorm = Normalize(vmin=-1, vmax=1)\neof1[0].plot.contourf(ax=ax1, levels = clevs, cmap=plt.cm.RdBu_r,\n                         transform=ccrs.PlateCarree(), add_colorbar=True, norm=norm)\nax1.set_title('EOF1 expressed as covariance', fontsize=16)\nfig.axes[1].set_ylabel('')\nfig.axes[1].set_yticks(np.arange(-1,1.2,0.2))\n\n#Now let's scatter the proxy data\nEOF = pca.eigvecs[:, 0]\nax1.scatter(filtered_df2['lon'],filtered_df2['lat'], c =EOF, cmap=plt.cm.RdBu_r, transform=ccrs.PlateCarree(), norm=norm, s=400, edgecolor='k', linewidth=3)\n\n## Let's plot the PCS!\nPC = pca.pcs[:, 0]\n\n\nax2 = fig.add_subplot(gs[0, 1:],)\ntime_model = np.arange(910,1660,20)\nts1 = pyleo.Series(time = time_model, value =  pcs[:, 0], time_name = 'Years', time_unit = 'CE', value_name='PC1', label = 'CESM-LEM',verbose=False)\nts2 = pyleo.Series(time = mgs_common.series_list[0].time, value =  PC, time_name = 'Years', time_unit = 'CE', value_name='PC1', label = 'Proxy Data', verbose = False)\nts1.plot(ax=ax2, legend = True)\nts2.plot(ax=ax2, legend = True)\nax2.set_ylim([-1,1])\nax2.legend()\n# Layout adjustments and display the figure\nplt.tight_layout()\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/paleopca#model-data-comparison","position":27},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/paleopca#summary","position":28},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Summary"},"content":"In this Cookbook, you learned to run PCA analysis on gridded and point datasets to allow for model-data comparison. Although this was focued on the paleoclimate domain, the technique is broadly applicable to the instrumental era.\n\n","type":"content","url":"/notebooks/paleopca#summary","position":29},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/paleopca#resources-and-references","position":30},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl2":"Resources and references"},"content":"","type":"content","url":"/notebooks/paleopca#resources-and-references","position":31},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Model Output","lvl2":"Resources and references"},"type":"lvl3","url":"/notebooks/paleopca#model-output","position":32},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Model Output","lvl2":"Resources and references"},"content":"CESM LME: Otto-Bliesner, B.L., E.C. Brady, J. Fasullo, A. Jahn, L. Landrum, S. Stevenson, N. Rosenbloom, A. Mai, G. Strand. Climate Variability and Change since 850 C.E. : An Ensemble Approach with the Community Earth System Model (CESM), Bulletin of the American Meteorological Society, 735-754 (May 2016 issue)","type":"content","url":"/notebooks/paleopca#model-output","position":33},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Proxy Compilations","lvl2":"Resources and references"},"type":"lvl3","url":"/notebooks/paleopca#proxy-compilations","position":34},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Proxy Compilations","lvl2":"Resources and references"},"content":"Iso2k: Konecky, B. L., McKay, N. P., Churakova (Sidorova), O. V., Comas-Bru, L., Dassié, E. P., DeLong, K. L., Falster, G. M., Fischer, M. J., Jones, M. D., Jonkers, L., Kaufman, D. S., Leduc, G., Managave, S. R., Martrat, B., Opel, T., Orsi, A. J., Partin, J. W., Sayani, H. R., Thomas, E. K., Thompson, D. M., Tyler, J. J., Abram, N. J., Atwood, A. R., Cartapanis, O., Conroy, J. L., Curran, M. A., Dee, S. G., Deininger, M., Divine, D. V., Kern, Z., Porter, T. J., Stevenson, S. L., von Gunten, L., and Iso2k Project Members: The Iso2k database: a global compilation of paleo-δ18O and δ2H records to aid understanding of Common Era climate, Earth Syst. Sci. Data, 12, 2261–2288, \n\nKonecky et al. (2020), 2020.\n\nPAGES2kTemperature: PAGES2k Consortium. A global multiproxy database for temperature reconstructions of the Common Era. Sci. Data 4:170088 \n\ndoi: 10.1038/sdata.2017.88 (2017).\n\nCoralHydro2k: Walter, R. M., Sayani, H. R., Felis, T., Cobb, K. M., Abram, N. J., Arzey, A. K., Atwood, A. R., Brenner, L. D., Dassié, É. P., DeLong, K. L., Ellis, B., Emile-Geay, J., Fischer, M. J., Goodkin, N. F., Hargreaves, J. A., Kilbourne, K. H., Krawczyk, H., McKay, N. P., Moore, A. L., Murty, S. A., Ong, M. R., Ramos, R. D., Reed, E. V., Samanta, D., Sanchez, S. C., Zinke, J., and the PAGES CoralHydro2k Project Members: The CoralHydro2k database: a global, actively curated compilation of coral δ18O and Sr ∕ Ca proxy records of tropical ocean hydrology and temperature for the Common Era, Earth Syst. Sci. Data, 15, 2081–2116, \n\nWalter et al. (2023), 2023.\n\nSISAL: Comas-Bru, L., Rehfeld, K., Roesch, C., Amirnezhad-Mozhdehi, S., Harrison, S. P., Atsawawaranunt, K., Ahmad, S. M., Brahim, Y. A., Baker, A., Bosomworth, M., Breitenbach, S. F. M., Burstyn, Y., Columbu, A., Deininger, M., Demény, A., Dixon, B., Fohlmeister, J., Hatvani, I. G., Hu, J., Kaushal, N., Kern, Z., Labuhn, I., Lechleitner, F. A., Lorrey, A., Martrat, B., Novello, V. F., Oster, J., Pérez-Mejías, C., Scholz, D., Scroxton, N., Sinha, N., Ward, B. M., Warken, S., Zhang, H., and SISAL Working Group members: SISALv2: a comprehensive speleothem isotope database with multiple age–depth models, Earth Syst. Sci. Data, 12, 2579–2606, \n\nComas-Bru et al. (2020), 2020.","type":"content","url":"/notebooks/paleopca#proxy-compilations","position":35},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Software","lvl2":"Resources and references"},"type":"lvl3","url":"/notebooks/paleopca#software","position":36},{"hierarchy":{"lvl1":"Investigating interhemispheric precipitation changes over the past millennium","lvl3":"Software","lvl2":"Resources and references"},"content":"xarray: Hoyer, S., & Joseph, H. (2017). xarray: N-D labeled Arrays and Datasets in Python. Journal of Open Research Software, 5(1). \n\nHoyer & Hamman (2017)\n\nPyleoclim:\n\nKhider, D., Emile-Geay, J., Zhu, F., James, A., Landers, J., Ratnakar, V., & Gil, Y. (2022). Pyleoclim: Paleoclimate timeseries analysis and visualization with Python. Paleoceanography and Paleoclimatology, 37, e2022PA004509. \n\nKhider et al. (2022)\n\nKhider, D., Emile-Geay, J., Zhu, F., James, A., Landers, J., Kwan, M., Athreya, P., McGibbon, R., & Voirol, L. (2024). Pyleoclim: A Python package for the analysis and visualization of paleoclimate data (Version v1.0.0) [Computer software]. \n\nKhider et al. (2025)\n\neofs: Dawson, A. (2016) ‘eofs: A Library for EOF Analysis of Meteorological, Oceanographic, and Climate Data’, Journal of Open Research Software, 4(1), p. e14. Available at: \n\nDawson (2016).","type":"content","url":"/notebooks/paleopca#software","position":37}]}